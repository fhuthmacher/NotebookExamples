{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be8da33c-eeb6-4d72-a0fc-89f9fb6a19fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# LLM Information Extraction Evaluation\n",
    "## Status: Experimental\n",
    "    \n",
    "This notebook attempts to provide a systematic approach for model evaluation, startig from a given business problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24283ee-03c6-45bf-a593-325a309e7ed5",
   "metadata": {},
   "source": [
    "Evaluating LLMs is a complex task. While there are benchmarks (e.g. https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard or https://crfm.stanford.edu/helm/latest/)\n",
    " available that provide a general view of how a particular LLM would perform in some common NLP tasks, most of evaluation frameworks/approaches are still evolving and none of them cover all aspects. It is important to understand which benchmark is the most relevant to a given use case, and to be mindful of the social aspects as well, and ultimately to evaluate LLMs against the data of your specific use case.\n",
    "    \n",
    "Business problem: \n",
    "Let's assume a financial analyst wants to use financial statements (balance sheets, income statements, operational reports, annual reports) to better understand the financial strength of a company to help assess risk and guide future investment decisisions.\n",
    "\n",
    "To do this efficiently they need to extract information from these documents which consist largely of unstructured text.\n",
    "This notebook focuses on Amazon's annual report, but the this approach can easily be adopted to other documents and an entire corpus of documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad47020c-9266-4740-99c2-0d330b90d460",
   "metadata": {},
   "source": [
    "# Options\n",
    "There are various options for you to choose from in this process:\n",
    "\n",
    "- 1) Embeddings: Currently we are using amazon.titan-embed-text-v1, but will switch to amazon.titan-e1t-medium once generally available. \n",
    "- 2) Text Splitter: We used TokenTextSplitter from langchain. Other supported options within langchain are CharacterTextSplitter, RecursiveCharacterTextSplitter, or RecursiveCharacterTextSplitter. Which Splitter works best will vary based on your use case and source data types. In addition there are other libraries like unstructured or eparse available that can further improve retrieval relevance.\n",
    "- 3) Vector Store: We used OpenSearch Serverless as our vector database to store embeddings. And while there are many vector databases available, you typically don't need a dedicated vector database, rather you can leverage a database that already hosts your data and supports vetor search such as PG Vector with RDS or OpenSearch. Data gravity is definitely a strong decision factor.  \n",
    "- 4) Retrievers: OpenSearch VectoreStoreRetriver using KNN for similarity search. In general to retrieve text, there are two search types: “similarity” or “mmr”. search_type=\"similarity\" uses similarity search and the retriever object where it selects text chunk vectors that are most similar to the question vector. search_type=\"mmr\" uses the maximum marginal relevance search where it optimizes for similarity to query AND diversity among selected documents.\n",
    "- 5) Chain Type: The default chain_type=\"stuff\" uses ALL of the text from the documents in the prompt. This might work fine for information extraction within one document, but will not work for information extraction from very large documents or a large corpus of documents. This is where the \"map_reduce\" chain type comes in. map_reduce separates texts into batches and feeds each batch with the question to the LLM separately, and comes up with the final answer based on the answers from each batch. In contrast the \"refine\" chain type separates texts into batches, feeds the first batch to LLM, and feeds the answer and the second batch to LLM. It refines the answer by going through all the batches. And lastly, \"map-rerank\"  separates texts into batches, feeds each batch to LLM, returns a score of how fully it answers the question, and comes up with the final answer based on the high-scored answers from each batch.\n",
    "- 6) Prompt Template: In addition to the model parameter size, model type (instruct, chat, light, instant, hf), precision (fp32, fp16), and quantization itself and the options referenced above, there are other variables that impact the response of an LLM, including:\n",
    "Model parameters: Maximum tokens, temperature, top-p, top-k, and frequency penalty\n",
    "User prompt: Changing even a single word or punctuation may result in vastly different responses\n",
    "Prompt template: Determines tone, tenor, pace, mood, voice, syntax, diction, format, and length of response and helps enforce the use of the supplied contextual reference\n",
    "\n",
    "\n",
    "TO DO: Add guidance/documentation for PromptTemplate - Dan - open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6dd86c-115c-49b9-b112-548edf312d33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# install dependencies\n",
    "%pip uninstall awscli boto3 botocore langchain  -y\n",
    "\n",
    "%pip install --no-build-isolation --force-reinstall \\\n",
    "    \"boto3>=1.28.57\" \\\n",
    "    \"awscli>=1.29.57\" \\\n",
    "    \"botocore>=1.31.57\"\n",
    "\n",
    "%pip install --quiet langchain==0.0.309 --force-reinstall\n",
    "%pip install langsmith tiktoken nltk python-dotenv xmltodict requests-aws4auth pypdf opensearch-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ba52a1c8-3b25-4bfa-bbff-5bbbd5de31c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# restart kernel to ensure proper version of libraries is loaded\n",
    "from IPython.display import display_html\n",
    "def restartkernel() :\n",
    "    display_html(\"<script>Jupyter.notebook.kernel.restart()</script>\",raw=True)\n",
    "restartkernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6b6646c5-8ccf-4e0b-8ea8-0501c379d551",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awscli                               1.29.57\n",
      "boto3                                1.28.57\n",
      "botocore                             1.31.57\n",
      "langchain                            0.0.305\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep -E \"awscli|boto3|botocore|langchain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8e938c8c-5e0b-483c-9efd-84c7c9d4e3bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "# load environment variables \n",
    "import boto3\n",
    "import os\n",
    "import botocore\n",
    "from botocore.config import Config\n",
    "import langchain\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain.llms import SagemakerEndpoint\n",
    "from langchain.llms.sagemaker_endpoint import LLMContentHandler\n",
    "from typing import Dict\n",
    "\n",
    "import json\n",
    "import requests\n",
    "import csv\n",
    "import time\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import sys\n",
    "\n",
    "from langchain.llms import Bedrock\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv('dev.env'),override=True)\n",
    "\n",
    "session = sagemaker.Session()\n",
    "bucket = session.default_bucket()\n",
    "\n",
    "os.environ['LANGCHAIN_ASSUME_ROLE'] = os.getenv('LANGCHAIN_ASSUME_ROLE')\n",
    "os.environ['BEDROCK_REGION_NAME'] = os.getenv('BEDROCK_REGION_NAME') # 'us-west-2'\n",
    "os.environ['BEDROCK_ENDPOINT_URL'] = os.getenv('BEDROCK_ENDPOINT_URL') # 'https://prod.us-west-2.frontend.bedrock.aws.dev'\n",
    "os.environ['OPENSEARCH_COLLECTION'] = os.getenv('OPENSEARCH_COLLECTION')\n",
    "os.environ['OPENSEARCH_REGION'] = os.getenv('OPENSEARCH_REGION')\n",
    "\n",
    "# Initialize Bedrock runtime\n",
    "config = Config(\n",
    "   retries = {\n",
    "      'max_attempts': 8\n",
    "   }\n",
    ")\n",
    "bedrock_runtime = boto3.client(\n",
    "        service_name=\"bedrock-runtime\",\n",
    "        region_name=os.environ.get(\"BEDROCK_REGION_NAME\", None),\n",
    "        config=config\n",
    ")\n",
    "\n",
    "# Initialize the DynamoDB client\n",
    "dynamodb_client = boto3.client('dynamodb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5398b2-5e7a-44b8-bfe5-312ec7d7080f",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\"https://d3q8adh3y5sxpk.cloudfront.net/meetingrecordings/modelevaluation/Slide1.jpeg\" alt=\"LLM selection process\" width=\"900\" height=\"550\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a50061-31f3-4116-a816-08567db79eb4",
   "metadata": {},
   "source": [
    "# 1) Quick short listing\n",
    "Based on the LLM capabilties select a dozen models for a small test "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cf738e-80bc-4876-9510-b6645e5e64a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\"https://d3q8adh3y5sxpk.cloudfront.net/meetingrecordings/modelevaluation/Slide2.jpeg\" alt=\"LLM capabilities\" width=\"900\" height=\"550\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8822f01a-500d-41cc-892b-7e6986351dde",
   "metadata": {
    "tags": []
   },
   "source": [
    "TO DO: Add guidance/documentation on why we selected the below 3 LLMs for this use case - Harsha - open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c9f1edb6-2102-48a2-bede-ffabd3caa462",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## 1a. Initialize llm01 = Claude-v2\n",
    "inference_modifier = {\n",
    "    \"max_tokens_to_sample\": 545,\n",
    "    \"temperature\": 0,\n",
    "    \"stop_sequences\": [\"\\n\\nHuman\"],\n",
    "}\n",
    "\n",
    "llm01 = Bedrock( #create a Bedrock llm client\n",
    "    region_name=os.environ.get(\"BEDROCK_REGION_NAME\"), #sets the region name (if not the default)\n",
    "    endpoint_url=os.environ.get(\"BEDROCK_ENDPOINT_URL\"), #sets the endpoint URL (if necessary)\n",
    "    model_id=\"anthropic.claude-v2\",\n",
    "    model_kwargs=inference_modifier\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1b23080a-7351-4a7e-a018-bcf5e4bc3ccf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## 1b. Initialize Cohere Command\n",
    "## below is not available yet in langchain, therefore we are creating a custom LLM wrapper\n",
    "\n",
    "#llm02 = Bedrock( #create a Bedrock llm client\n",
    "#    region_name=os.environ.get(\"BEDROCK_REGION_NAME\"),\n",
    "#    endpoint_url=os.environ.get(\"BEDROCK_ENDPOINT_URL\"),\n",
    "#    model_id=\"cohere.command-text-v14\",\n",
    "#)\n",
    "\n",
    "from typing import Any, List, Mapping, Optional\n",
    "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
    "from langchain.llms.base import LLM\n",
    "\n",
    "class CohereLLM(LLM):\n",
    "    max_tokens: int\n",
    "    temperature: int\n",
    "    \n",
    "    @property\n",
    "    def _identifying_params(self) -> Mapping[str, Any]:\n",
    "        \"\"\"Get the identifying parameters.\"\"\"\n",
    "        return {\"max_tokens\": self.max_tokens,\"temperature\": self.temperature}\n",
    "    \n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"cohere.command-text-v14\"\n",
    "\n",
    "    def _call(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> str:\n",
    "        if stop is not None:\n",
    "            raise ValueError(\"stop kwargs are not permitted.\")\n",
    "            \n",
    "        \n",
    "        modelId = 'cohere.command-text-v14' # change this to use a different version from the model provider\n",
    "\n",
    "        accept = '*/*'\n",
    "        contentType = 'application/json'\n",
    "        prompt_data = f\"\"\"Human: {prompt}\n",
    "                         Assistant: \n",
    "                      \"\"\"\n",
    "\n",
    "        model_kwargs = {\n",
    "                        \"max_tokens\": self.max_tokens,\n",
    "                        \"temperature\": self.temperature,\n",
    "\n",
    "                       }\n",
    "        model_kwargs[\"prompt\"] = prompt_data\n",
    "        body = json.dumps(model_kwargs)\n",
    "        response = bedrock_runtime.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "        response_body = json.loads(response.get('body').read())\n",
    "        try:\n",
    "            result = response_body['generations'][0]['text'].strip()\n",
    "        except:\n",
    "            result = ''\n",
    "        return result\n",
    "\n",
    "\n",
    "llm02 = CohereLLM(max_tokens=545,temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4ee8fa5b-6187-4d6d-a807-a36b001ce08c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## 1c. Initialize SageMaker model - Llama-7B\n",
    "class ContentHandler(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, prompt: str, model_kwargs: Dict) -> bytes:\n",
    "        input_str = json.dumps({\n",
    "            \"inputs\": [[\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ]],\n",
    "            \"parameters\": {\"max_new_tokens\": model_kwargs['max_new_tokens'], \"top_p\": model_kwargs['top_p'], \"temperature\": model_kwargs['temperature']}\n",
    "        })\n",
    "        return input_str.encode(\"utf-8\")\n",
    "\n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        response_json = response_json[0]['generation']['content']\n",
    "        \n",
    "        return response_json\n",
    "\n",
    "content_handler = ContentHandler()\n",
    "\n",
    "llm03=SagemakerEndpoint(\n",
    "     endpoint_name=\"jumpstart-dft-meta-textgeneration-llama-2-7b-f\", \n",
    "     region_name=\"us-east-1\",\n",
    "     model_kwargs={\"max_new_tokens\": 545, \"top_p\": 0.9, \"temperature\": 0},\n",
    "     endpoint_kwargs={\"CustomAttributes\": 'accept_eula=true'},\n",
    "     content_handler=content_handler\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d4b8deba-3ad2-4fc1-8674-104440d4145e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mInput:\u001b[0m\n",
      "\n",
      "    Amazon operates three main business segments: North America retail sales, International retail sales, and Amazon Web Services (\"AWS\"). \n",
      "\n",
      "    Risk Factors:\n",
      "    - Intense competition globally in all business areas - Amazon competes with various companies including physical retailers, e-commerce companies, technology companies, device makers, digital content creators, delivery/logistics providers, and more. \n",
      "    - International expansion brings regulatory, infrastructure, and operational risks. Amazon must comply with complex regulations abroad and faces limitations related to infrastructure, local business practices, laws, and legal liability.\n",
      "    - Demand fluctuation strains operations. Amazon's business sees seasonal sales spikes that test fulfillment capacity. Failure to meet demand can significantly impact sales.\n",
      "    - Reliance on sellers exposes Amazon to fraud risk. Amazon could face liability for seller violations of policies or fraud. \n",
      "    - Protecting IP is challenging. Amazon relies on IP protections globally but enforcement is difficult. Others claim Amazon infringes their IP rights through litigation. \n",
      "    - Foreign exchange fluctuations impact results. Amazon has extensive international operations and holds foreign cash, so currency changes affect financials.\n",
      "    - Rapid expansion strains resources. Adding employees, products/services and infrastructure complexity taxes Amazon's resources. \n",
      "    - Accounting requires estimates. Financial reporting relies on certain estimates that may prove incorrect over time.\n",
      "    - Competitive hiring is critical. Amazon needs to attract and retain technical and executive talent in a tight labor market.\n",
      "    - Acquisition integration is difficult. Adding companies brings risks during integration and may not meet financial expectations.\n",
      "    - Security threats bring business risk. Amazon faces cyber attacks and threats requiring ongoing security investments.\n",
      "    - Lawsuits and claims may arise. Amazon faces litigation, investigations, and other claims that could result in damages.\n",
      "\n",
      "    Key areas of investment: devices, digital content, international physical/digital retail expansion, AWS growth, advertising, supply chain, and emerging areas like autonomous vehicles.\n",
      "\n",
      "    Given the above information, answer the following question:\n",
      "    What are the three main business units of the company?\n",
      "\n",
      "\u001b[1mBedrock\u001b[0m\n",
      "Params: {}\n",
      "\u001b[36;1m\u001b[1;3m Based on the information provided, the three main business units of Amazon are:\n",
      "\n",
      "1. North America retail sales\n",
      "2. International retail sales  \n",
      "3. Amazon Web Services (AWS)\u001b[0m\n",
      "\n",
      "\u001b[1mCohereLLM\u001b[0m\n",
      "Params: {'max_tokens': 545, 'temperature': 0}\n",
      "\u001b[33;1m\u001b[1;3mThe answer is Amazon operates three main business segments: North America retail sales, International retail sales, and Amazon Web Services (\"AWS\").\u001b[0m\n",
      "\n",
      "\u001b[1mSagemakerEndpoint\u001b[0m\n",
      "Params: {'endpoint_name': 'jumpstart-dft-meta-textgeneration-llama-2-7b-f', 'model_kwargs': {'max_new_tokens': 545, 'top_p': 0.9, 'temperature': 0}}\n",
      "\u001b[38;5;200m\u001b[1;3m Thank you for providing the information about Amazon's business segments. Based on the information provided, the three main business units of Amazon are:\n",
      "\n",
      "1. North America Retail Sales: This includes Amazon's e-commerce business in the United States, Canada, and Mexico.\n",
      "2. International Retail Sales: This includes Amazon's e-commerce business outside of North America, including Europe, Asia, and other international markets.\n",
      "3. Amazon Web Services (AWS): This includes Amazon's cloud computing and other technology services offered to businesses, governments, and other organizations.\n",
      "\n",
      "I hope this answer is helpful! Let me know if you have any other questions.\u001b[0m\n",
      "\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\n",
      "    Amazon operates three main business segments: North America retail sales, International retail sales, and Amazon Web Services (\"AWS\"). \n",
      "\n",
      "    Risk Factors:\n",
      "    - Intense competition globally in all business areas - Amazon competes with various companies including physical retailers, e-commerce companies, technology companies, device makers, digital content creators, delivery/logistics providers, and more. \n",
      "    - International expansion brings regulatory, infrastructure, and operational risks. Amazon must comply with complex regulations abroad and faces limitations related to infrastructure, local business practices, laws, and legal liability.\n",
      "    - Demand fluctuation strains operations. Amazon's business sees seasonal sales spikes that test fulfillment capacity. Failure to meet demand can significantly impact sales.\n",
      "    - Reliance on sellers exposes Amazon to fraud risk. Amazon could face liability for seller violations of policies or fraud. \n",
      "    - Protecting IP is challenging. Amazon relies on IP protections globally but enforcement is difficult. Others claim Amazon infringes their IP rights through litigation. \n",
      "    - Foreign exchange fluctuations impact results. Amazon has extensive international operations and holds foreign cash, so currency changes affect financials.\n",
      "    - Rapid expansion strains resources. Adding employees, products/services and infrastructure complexity taxes Amazon's resources. \n",
      "    - Accounting requires estimates. Financial reporting relies on certain estimates that may prove incorrect over time.\n",
      "    - Competitive hiring is critical. Amazon needs to attract and retain technical and executive talent in a tight labor market.\n",
      "    - Acquisition integration is difficult. Adding companies brings risks during integration and may not meet financial expectations.\n",
      "    - Security threats bring business risk. Amazon faces cyber attacks and threats requiring ongoing security investments.\n",
      "    - Lawsuits and claims may arise. Amazon faces litigation, investigations, and other claims that could result in damages.\n",
      "\n",
      "    Key areas of investment: devices, digital content, international physical/digital retail expansion, AWS growth, advertising, supply chain, and emerging areas like autonomous vehicles.\n",
      "\n",
      "    Given the above information, answer the following question:\n",
      "    What were the company's key areas of investment?\n",
      "\n",
      "\u001b[1mBedrock\u001b[0m\n",
      "Params: {}\n",
      "\u001b[36;1m\u001b[1;3m Based on the information provided, Amazon's key areas of investment were:\n",
      "\n",
      "- Devices - Amazon invests in making devices like Kindle e-readers, Fire tablets, Echo speakers, and Ring security cameras.\n",
      "\n",
      "- Digital content - Amazon invests in digital content like movies, TV shows, music, books, and games for its Prime Video, Amazon Music, Audible, Kindle, and Amazon Appstore offerings.\n",
      "\n",
      "- International physical/digital retail expansion - Amazon invests in expanding its e-commerce operations and physical stores internationally. \n",
      "\n",
      "- AWS growth - Amazon invests heavily in expanding its Amazon Web Services cloud computing business.\n",
      "\n",
      "- Advertising - Amazon is investing in building its advertising business on its platforms.\n",
      "\n",
      "- Supply chain/logistics - Amazon invests billions in fulfillment centers, transportation capabilities, and supply chain technology.\n",
      "\n",
      "- Emerging areas like autonomous vehicles - Amazon invests in R&D for emerging technologies like self-driving vehicles.\u001b[0m\n",
      "\n",
      "\u001b[1mCohereLLM\u001b[0m\n",
      "Params: {'max_tokens': 545, 'temperature': 0}\n",
      "\u001b[33;1m\u001b[1;3mThe answer is Key areas of investment: devices, digital content, international physical/digital retail expansion, AWS growth, advertising, supply chain, and emerging areas like autonomous vehicles.\u001b[0m\n",
      "\n",
      "\u001b[1mSagemakerEndpoint\u001b[0m\n",
      "Params: {'endpoint_name': 'jumpstart-dft-meta-textgeneration-llama-2-7b-f', 'model_kwargs': {'max_new_tokens': 545, 'top_p': 0.9, 'temperature': 0}}\n",
      "\u001b[38;5;200m\u001b[1;3m Based on the information provided, Amazon's key areas of investment are:\n",
      "\n",
      "1. Devices: Amazon has invested in the development and improvement of its devices, such as the Echo smart speaker and the Fire TV stick.\n",
      "2. Digital content: Amazon has invested in the creation and distribution of digital content, including music, movies, and TV shows, through its subsidiary Amazon Studios.\n",
      "3. International retail sales: Amazon has expanded its physical retail presence internationally, including the acquisition of Whole Foods Market in 2017.\n",
      "4. AWS growth: Amazon has invested in the growth of its cloud computing division, Amazon Web Services (AWS), which provides a range of cloud-based services to businesses and organizations.\n",
      "5. Advertising: Amazon has invested in its advertising business, which includes sponsored products and sponsored brands on its platform.\n",
      "6. Supply chain: Amazon has invested in improving its supply chain and logistics capabilities, including the acquisition of the logistics company, Deliveroo.\n",
      "7. Emerging areas: Amazon has also invested in emerging areas such as autonomous vehicles, through its subsidiary, Zoox.\n",
      "\n",
      "It's worth noting that these are the key areas of investment mentioned in the provided information, but Amazon may have other areas of investment as well.\u001b[0m\n",
      "\n",
      "\u001b[1mInput:\u001b[0m\n",
      "\n",
      "    Amazon operates three main business segments: North America retail sales, International retail sales, and Amazon Web Services (\"AWS\"). \n",
      "\n",
      "    Risk Factors:\n",
      "    - Intense competition globally in all business areas - Amazon competes with various companies including physical retailers, e-commerce companies, technology companies, device makers, digital content creators, delivery/logistics providers, and more. \n",
      "    - International expansion brings regulatory, infrastructure, and operational risks. Amazon must comply with complex regulations abroad and faces limitations related to infrastructure, local business practices, laws, and legal liability.\n",
      "    - Demand fluctuation strains operations. Amazon's business sees seasonal sales spikes that test fulfillment capacity. Failure to meet demand can significantly impact sales.\n",
      "    - Reliance on sellers exposes Amazon to fraud risk. Amazon could face liability for seller violations of policies or fraud. \n",
      "    - Protecting IP is challenging. Amazon relies on IP protections globally but enforcement is difficult. Others claim Amazon infringes their IP rights through litigation. \n",
      "    - Foreign exchange fluctuations impact results. Amazon has extensive international operations and holds foreign cash, so currency changes affect financials.\n",
      "    - Rapid expansion strains resources. Adding employees, products/services and infrastructure complexity taxes Amazon's resources. \n",
      "    - Accounting requires estimates. Financial reporting relies on certain estimates that may prove incorrect over time.\n",
      "    - Competitive hiring is critical. Amazon needs to attract and retain technical and executive talent in a tight labor market.\n",
      "    - Acquisition integration is difficult. Adding companies brings risks during integration and may not meet financial expectations.\n",
      "    - Security threats bring business risk. Amazon faces cyber attacks and threats requiring ongoing security investments.\n",
      "    - Lawsuits and claims may arise. Amazon faces litigation, investigations, and other claims that could result in damages.\n",
      "\n",
      "    Key areas of investment: devices, digital content, international physical/digital retail expansion, AWS growth, advertising, supply chain, and emerging areas like autonomous vehicles.\n",
      "\n",
      "    Given the above information, answer the following question:\n",
      "    What is the single most important risk the company faces in the next year?\n",
      "\n",
      "\u001b[1mBedrock\u001b[0m\n",
      "Params: {}\n",
      "\u001b[36;1m\u001b[1;3m Based on the risk factors outlined, I would say that Amazon's most important risk in the next year is likely the intense competition the company faces globally in all of its business segments. \n",
      "\n",
      "Amazon operates in highly competitive markets, competing with various physical and online retailers, technology companies, delivery providers, and more. As new competitors emerge and existing ones expand their offerings, Amazon faces significant pressure to innovate, provide value, and maintain its market position across its retail, devices, content, and cloud computing businesses. \n",
      "\n",
      "Navigating this competitive landscape globally requires massive ongoing investments and strategic focus from Amazon. Failure to compete effectively could lead to loss of market share, lower revenues and profits, and declining brand value over time. Given the rapid pace of change in the industry and Amazon's wide range of competitors, competition represents the most crucial risk the company must manage well in the next year to maintain its leadership.\u001b[0m\n",
      "\n",
      "\u001b[1mCohereLLM\u001b[0m\n",
      "Params: {'max_tokens': 545, 'temperature': 0}\n",
      "\u001b[33;1m\u001b[1;3mThe answer is Amazon faces a number of risks, but the most important one is the risk of international expansion. Amazon has been expanding internationally for years, and while it has been successful in many ways, it has also faced a number of challenges. These challenges include regulatory and infrastructure risks, as well as operational risks. As Amazon continues to expand internationally, it is likely to face even more of these challenges, and it will be important for the company to manage these risks effectively.\u001b[0m\n",
      "\n",
      "\u001b[1mSagemakerEndpoint\u001b[0m\n",
      "Params: {'endpoint_name': 'jumpstart-dft-meta-textgeneration-llama-2-7b-f', 'model_kwargs': {'max_new_tokens': 545, 'top_p': 0.9, 'temperature': 0}}\n",
      "\u001b[38;5;200m\u001b[1;3m Thank you for providing the information about Amazon's business segments and risk factors. Based on the information provided, the single most important risk the company faces in the next year is likely to be intense competition globally in all business areas. Amazon competes with various companies including physical retailers, e-commerce companies, technology companies, device makers, digital content creators, delivery/logistics providers, and more, which can lead to significant competition in all areas of its business. This competition can impact Amazon's market share, pricing power, and overall financial performance.\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1d. Start with a simple example - no prompt template or RAG, just passing the prompts below directly into the LLMs\n",
    "from langchain import LLMChain, HuggingFaceHub, Prompt\n",
    "from langchain.model_laboratory import ModelLaboratory\n",
    "\n",
    "llms = [\n",
    "    llm01,\n",
    "    llm02,\n",
    "    llm03\n",
    "]\n",
    "\n",
    "test_prompts = [ \"What are the three main business units of the company?\",\n",
    "    \"What were the company's key areas of investment?\",\n",
    "    \"What is the single most important risk the company faces in the next year?\"]\n",
    "\n",
    "model_lab = ModelLaboratory.from_llms(llms)\n",
    "\n",
    "for question in test_prompts:\n",
    "    prompt = f\"\"\"\n",
    "    Amazon operates three main business segments: North America retail sales, International retail sales, and Amazon Web Services (\"AWS\"). \n",
    "\n",
    "    Risk Factors:\n",
    "    - Intense competition globally in all business areas - Amazon competes with various companies including physical retailers, e-commerce companies, technology companies, device makers, digital content creators, delivery/logistics providers, and more. \n",
    "    - International expansion brings regulatory, infrastructure, and operational risks. Amazon must comply with complex regulations abroad and faces limitations related to infrastructure, local business practices, laws, and legal liability.\n",
    "    - Demand fluctuation strains operations. Amazon's business sees seasonal sales spikes that test fulfillment capacity. Failure to meet demand can significantly impact sales.\n",
    "    - Reliance on sellers exposes Amazon to fraud risk. Amazon could face liability for seller violations of policies or fraud. \n",
    "    - Protecting IP is challenging. Amazon relies on IP protections globally but enforcement is difficult. Others claim Amazon infringes their IP rights through litigation. \n",
    "    - Foreign exchange fluctuations impact results. Amazon has extensive international operations and holds foreign cash, so currency changes affect financials.\n",
    "    - Rapid expansion strains resources. Adding employees, products/services and infrastructure complexity taxes Amazon's resources. \n",
    "    - Accounting requires estimates. Financial reporting relies on certain estimates that may prove incorrect over time.\n",
    "    - Competitive hiring is critical. Amazon needs to attract and retain technical and executive talent in a tight labor market.\n",
    "    - Acquisition integration is difficult. Adding companies brings risks during integration and may not meet financial expectations.\n",
    "    - Security threats bring business risk. Amazon faces cyber attacks and threats requiring ongoing security investments.\n",
    "    - Lawsuits and claims may arise. Amazon faces litigation, investigations, and other claims that could result in damages.\n",
    "\n",
    "    Key areas of investment: devices, digital content, international physical/digital retail expansion, AWS growth, advertising, supply chain, and emerging areas like autonomous vehicles.\n",
    "\n",
    "    Given the above information, answer the following question:\n",
    "    \"\"\" + question\n",
    "    \n",
    "    model_lab.compare(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ad89dc-8071-4f1c-97b0-71b4cefb349e",
   "metadata": {},
   "source": [
    "# 2) use case specific benchmark\n",
    "\n",
    "Now after quickly testing the shortlisted LLMs, let's take the top 3 LLMs based on our initial results and LLM capabilities and perform a use case specific benchmark.\n",
    "\n",
    "In our scenario the top 3 LLMs are Llama 2 13B, Cohere Command, and Anthropic Claude V2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae175dc-9e2c-4003-bd0d-42c0a5fc6f42",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\"https://d3q8adh3y5sxpk.cloudfront.net/meetingrecordings/modelevaluation/Slide7.jpeg\" alt=\"GeneratePrompts\" width=\"900\" height=\"550\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26bf212-5755-43ef-b5b6-ebfa3d73213d",
   "metadata": {},
   "source": [
    "For our use case we happen to have labeled ground truth data which we can use for our test. Thus we can leverage classic ML-metrics to evaluate the performance of the different LLM pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "60611855-58f1-4568-b250-88ed113262e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['question', 'answer'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "## 2c. download ground truth dataset and insert into dynamodb table promptcatalog with columns prompt, context, output, evalationmetric, created_at,created_by\n",
    "import xmltodict\n",
    "url = 'https://d3q8adh3y5sxpk.cloudfront.net/meetingrecordings/modelevaluationdata/qsdata_200.xml'\n",
    "\n",
    "# Send an HTTP GET request to download the file\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (HTTP status code 200)\n",
    "if response.status_code == 200:        \n",
    "    xml_data = xmltodict.parse(response.text)\n",
    "\n",
    "# Convert the dictionary to a Pandas DataFrame\n",
    "qa_dataset = pd.DataFrame(xml_data['root']['row'])\n",
    "\n",
    "#show dataframe columns\n",
    "print(qa_dataset.columns)\n",
    "\n",
    "table_name = 'promptcatalog'\n",
    "prompts = []\n",
    "for row in qa_dataset.itertuples():\n",
    "    item = {\n",
    "        'prompt': str(row.question),\n",
    "        'context': 'amazon_10k_2023.pdf',\n",
    "        'output': str(row.answer),\n",
    "        'evaluationmetric': 'Accuracy'\n",
    "    }\n",
    "    prompts.append(item)\n",
    "\n",
    "save_prompts_to_dynamodb_table(table_name, prompts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a192af69-e892-4b15-b81a-cac2e4377b40",
   "metadata": {},
   "source": [
    "If you do not have a ground truth dataset, then you can generate one with the help of a LLM as shown in the following example notebook:  https://github.com/fhuthmacher/NotebookExamples/blob/main/GenerateQuestionsAndAnswers.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "11ce0eb2-08e4-4819-8959-f0cbada7ed66",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2d. download context / Amazon annual report\n",
    "import numpy as np\n",
    "import pypdf\n",
    "from langchain.text_splitter import CharacterTextSplitter, TokenTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader, PyPDFDirectoryLoader\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "files = [ \"https://d3q8adh3y5sxpk.cloudfront.net/meetingrecordings/modelevaluationdata/amazon_10k_2023.pdf\"]\n",
    "for url in files:\n",
    "    file_path = os.path.join(\"data\", url.rpartition(\"/\")[2])\n",
    "    urlretrieve(url, file_path)\n",
    "    \n",
    "\n",
    "loader = PyPDFDirectoryLoader(\"./data/\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1785eafa-b98f-4530-9ce2-cd3728ec1cef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TokenTextSplitter split documents in to 189 chunks.\n",
      "\n",
      "CharacterTextSplitter split documents in to 682 chunks.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 2e. Split documents into smaller chunks \n",
    "### Compare results/impact of Character split and TokenTextSplitter\n",
    "\n",
    "token_text_splitter = TokenTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "char_text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "\n",
    "token_text_list = token_text_splitter.split_documents(documents)\n",
    "char_text_list = char_text_splitter.split_documents(documents)\n",
    "    \n",
    "print(\"TokenTextSplitter split documents in to \" + str(len(token_text_list)) + \" chunks.\\n\")\n",
    "print(\"CharacterTextSplitter split documents in to \" + str(len(char_text_list)) + \" chunks.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4cd547b4-0ac3-4db5-a67e-02cae4bd150c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## 2f. create vectors and store them in our vector database (OpenSearch Serverless)\n",
    "### Connect to OpenSearchServerless\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth\n",
    "\n",
    "host = os.environ['OPENSEARCH_COLLECTION']  # serverless collection endpoint, without https://\n",
    "region = os.environ['OPENSEARCH_REGION']  # e.g. us-east-1\n",
    "\n",
    "service = 'aoss'\n",
    "credentials = boto3.Session().get_credentials()\n",
    "auth = AWSV4SignerAuth(credentials, region, service)\n",
    "\n",
    "aos_client = OpenSearch(\n",
    "    hosts=[{'host': host, 'port': 443}],\n",
    "    http_auth=auth,\n",
    "    use_ssl=True,\n",
    "    verify_certs=True,\n",
    "    connection_class=RequestsHttpConnection,\n",
    "    pool_maxsize=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "51156bab-2265-4bae-9783-543b4fcf7cb9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recreating index 'llmevaluation' on OpenSearch.\n"
     ]
    }
   ],
   "source": [
    "### Create a index in Amazon Opensearch Service \n",
    "\n",
    "# langchain version\n",
    "knn_index = {\n",
    "    \"settings\": {\n",
    "        \"index.knn\": True,\n",
    "        \n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"vector_field\": {\n",
    "                \"type\": \"knn_vector\",\n",
    "                \"dimension\": 1536,\n",
    "                \"store\": True\n",
    "            },\n",
    "            \"text\": {\n",
    "                \"type\": \"text\",\n",
    "                \"store\": True\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"llmevaluation\"\n",
    "try:\n",
    "    aos_client.indices.delete(index=index_name)\n",
    "    print(\"Recreating index '\" + index_name + \"' on OpenSearch.\")\n",
    "    aos_client.indices.create(index=index_name,body=knn_index,ignore=400)\n",
    "    aos_client.indices.get(index=index_name)\n",
    "except:\n",
    "    print(\"Index '\" + index_name + \"' not found. Creating index on OpenSearch.\")\n",
    "    aos_client.indices.create(index=index_name,body=knn_index,ignore=400)\n",
    "    aos_client.indices.get(index=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7a6c203c-496f-4d2d-9d3c-420ba8979e06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Use Titan Embeddings Model to generate embeddings\n",
    "\n",
    "from langchain.embeddings import BedrockEmbeddings\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "\n",
    "# LangChain requires AWS4Auth\n",
    "from requests_aws4auth import AWS4Auth\n",
    "def get_aws4_auth():\n",
    "    region = os.environ.get(\"Region\", os.environ[\"AWS_REGION\"])\n",
    "    service = \"aoss\"\n",
    "    credentials = boto3.Session().get_credentials()\n",
    "    return AWS4Auth(\n",
    "        credentials.access_key,\n",
    "        credentials.secret_key,\n",
    "        region,\n",
    "        service,\n",
    "        session_token=credentials.token,\n",
    "    )\n",
    "aws4_auth = get_aws4_auth()\n",
    "\n",
    "bedrock_embeddings = BedrockEmbeddings(client=bedrock_runtime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3efa7f74-9dfa-498c-bbbf-82d5e2dcb7ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ingested 189 documents from source char_text_list to target llmevaluation\n"
     ]
    }
   ],
   "source": [
    "## Insert embeddings into OpenSearch\n",
    "### For Serverless, please note is_aoss=True setting\n",
    "\n",
    "from langchain.vectorstores import OpenSearchVectorSearch\n",
    "\n",
    "full_opensearch_endpoint = 'https://' + os.environ['OPENSEARCH_COLLECTION']\n",
    "    \n",
    "# get embeddings and do insert to OpenSearch. Note: max 500 docs.\n",
    "def opensearch_insert(source_doc_list, target_index_name):\n",
    "    doc_search=OpenSearchVectorSearch.from_documents(\n",
    "            index_name = target_index_name,\n",
    "            documents=source_doc_list,\n",
    "            embedding=bedrock_embeddings,\n",
    "            opensearch_url=full_opensearch_endpoint,\n",
    "            http_auth=auth,\n",
    "            use_ssl=True,\n",
    "            verify_certs=True,\n",
    "            connection_class=RequestsHttpConnection,\n",
    "            timeout=60*3,\n",
    "            bulk_size=1000,\n",
    "            is_aoss=True\n",
    "        )\n",
    "    inserted_doc_length = len(source_doc_list)\n",
    "    input_doclist_name = f'{char_text_list=}'.split('=')[0]\n",
    "    print(f'ingested {inserted_doc_length} documents from source {input_doclist_name} to target {target_index_name}')\n",
    "    return doc_search\n",
    "\n",
    "doc_search=opensearch_insert(source_doc_list=token_text_list, target_index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8c56ef3c-a780-4ecf-856f-d8c5ab5f1f9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records found: 189.\n"
     ]
    }
   ],
   "source": [
    "### validate load\n",
    "res = aos_client.search(index=index_name, body={\"query\": {\"match_all\": {}}})\n",
    "print(\"Records found: %d.\" % res['hits']['total']['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "20efbb70-e968-4132-8f66-fd1760ea5941",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## 2e. Run prompts, and save responses & accuracy\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "        Human: Given report provided, please read it and analyse the content.\n",
    "        Please answer the following question: {question} basing the answer only on the information from the report\n",
    "        and return it inside <question_answer></question_answer> XML tags.\n",
    "\n",
    "        If a particular bit of information is not present, return an empty string.\n",
    "        Each returned answer should be concise, remove extra information if possible.\n",
    "        The report will be given between <report></report> XML tags.\n",
    "\n",
    "        <report>\n",
    "        {context}\n",
    "        </report>\n",
    "\n",
    "        Return the answer inside <question_answer></question_answer> XML tags.\n",
    "        Assistant:\"\"\"\n",
    "\n",
    "prompt_template_two = \"\"\"\n",
    "Human: \n",
    "You are a helpful, respectful, and honest assistant, dedicated to providing valuable and accurate information.\n",
    "\n",
    "Assistant:\n",
    "Understood. I will provide information based on the context given, without relying on prior knowledge.\n",
    "\n",
    "Human:\n",
    "If you don't see answer in the context just reply \"not available\" in XML tags.\n",
    "\n",
    "Assistant:\n",
    "Noted. I will respond with \"not available\" if the information is not available in the context.\n",
    "\n",
    "Human:\n",
    "Now read this context and answer the question and return the answer inside <question_answer></question_answer> XML tags. \n",
    "{context}\n",
    "\n",
    "Assistant:\n",
    "Based on the provided context above and information from the retriever source, I will provide the answer in  and return it inside <question_answer></question_answer> XML tags to the below question\n",
    "{question}\n",
    "\"\"\"\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template_two, input_variables=[\"question\", \"context\"]\n",
    ")\n",
    "\n",
    "## test query\n",
    "#query = \"Who is the CEO of Amazon?\"\n",
    "#qa.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b56466b-f351-4e67-9562-eba7287a0c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: \n",
    "## add different prompt templates and refactor evaluation pipeline to run for all llms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3539d4-4852-48b8-b412-aca750572794",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### run all LLMs through qa catalog\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "promptsdf = pd.DataFrame(prompts)\n",
    "\n",
    "predictions = []\n",
    "for llm in llms:\n",
    "    for row in promptsdf.itertuples():\n",
    "        query = row.prompt\n",
    "        qa = RetrievalQA.from_chain_type(\n",
    "                llm=llm,\n",
    "                chain_type=\"stuff\",\n",
    "                retriever=doc_search.as_retriever(),\n",
    "                chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "            )\n",
    "        result = qa.run(query)\n",
    "        \n",
    "        llm_name = ''\n",
    "        try:\n",
    "            llm_name = str(llm.model_id)\n",
    "        except:\n",
    "            try:\n",
    "                llm_name = str(llm.endpoint_name)\n",
    "            except:\n",
    "                try:\n",
    "                    llm_name = str(llm._llm_type)\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "        predictions.append({\n",
    "                \"query\": row.prompt,\n",
    "                \"llm\": str(llm_name),\n",
    "                \"context\": 'amazon_10k_2023.pdf',\n",
    "                \"output\": str(result),\n",
    "                \"trainingoutput\": str(row.output),\n",
    "                \"evaluationmetric\": \"\",\n",
    "                \"score\": \"\",\n",
    "                \"feedback\": \"\"\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8f3471e2-87df-4821-a675-64afb48b90fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### 3a. LLM evaluation using StringEvaluator\n",
    "from typing import Optional\n",
    "from langsmith.evaluation import StringEvaluator\n",
    "\n",
    "def jaccard_chars(output: str, answer: str) -> float:\n",
    "    try:\n",
    "        \"\"\"Naive Jaccard similarity between two strings.\"\"\"\n",
    "        prediction_chars = set(output.strip().lower())\n",
    "        answer_chars = set(answer.strip().lower())\n",
    "        intersection = prediction_chars.intersection(answer_chars)\n",
    "        union = prediction_chars.union(answer_chars)\n",
    "        return len(intersection) / len(union)\n",
    "    except:\n",
    "        return 1\n",
    " \n",
    "def grader(run_input: str, run_output: str, answer: Optional[str]) -> dict:\n",
    "    \"\"\"Compute the score and/or label for this run.\"\"\"\n",
    "    if answer is None:\n",
    "        value = \"AMBIGUOUS\"\n",
    "        score = 0.5\n",
    "    else:\n",
    "        score = jaccard_chars(run_output, answer)\n",
    "        value = \"CORRECT\" if score > 0.9 else \"INCORRECT\"\n",
    "    return dict(score=score, value=value)\n",
    "            \n",
    "string_eval_predictions = []\n",
    "for prediction in predictions:\n",
    "        evaluation_result = grader(prediction['query'], prediction['output'], prediction['trainingoutput'])    \n",
    "        string_eval_predictions.append({\n",
    "                \"query\": prediction['query'],\n",
    "                \"llm\": prediction['llm'],\n",
    "                \"context\": 'amazon_10k_2023.pdf',\n",
    "                \"output\": prediction['output'],\n",
    "                \"trainingoutput\": prediction['trainingoutput'],\n",
    "                \"evaluationmetric\": \"Naive Jaccard similarity between two strings\",\n",
    "                \"score\": str(evaluation_result['value']),\n",
    "                \"feedback\": \"similarity score= \" + str(evaluation_result['score']),\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "8a1776ba-96a1-41a5-94aa-44c809482469",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total # of chunks 10\n",
      "starting chunk 0\n",
      "starting chunk 1\n",
      "starting chunk 2\n",
      "starting chunk 3\n",
      "starting chunk 4\n",
      "starting chunk 5\n",
      "starting chunk 6\n",
      "starting chunk 7\n",
      "starting chunk 8\n",
      "starting chunk 9\n"
     ]
    }
   ],
   "source": [
    "### 3b. LLM evaluation using a mechanism for LLM-assisted evaluation to compare and score the responses \n",
    "### with the help of LLMs using langchain QAEvalChain\n",
    "\n",
    "from langchain.chat_models import BedrockChat\n",
    "from langchain.evaluation.qa import QAEvalChain\n",
    "import time\n",
    "inference_modifier = {\n",
    "    \"max_tokens_to_sample\": 545,\n",
    "    \"temperature\": 0,\n",
    "    \"top_k\": 250,\n",
    "    \"top_p\": 1,\n",
    "    \"stop_sequences\": [\"\\n\\nHuman\"],\n",
    "}\n",
    "\n",
    "llm = BedrockChat(model_id=\"anthropic.claude-v2\", model_kwargs=inference_modifier)\n",
    "\n",
    "eval_chain = QAEvalChain.from_llm(llm)\n",
    "\n",
    "qa_list = [{'query': item['query'], 'answer': item['trainingoutput']} for item in predictions]\n",
    "\n",
    "## to avoid read timeouts split qa_list into 50 records chunks \n",
    "## and execute eval_chain_evaluate function for each chunk with a wait period in betwwen\n",
    "chunk_size = 50\n",
    "graded_outputs = []\n",
    "qa_chunks = [qa_list[i:i + chunk_size] for i in range(0, len(qa_list), chunk_size)]\n",
    "qa_predictions = [predictions[i:i + chunk_size] for i in range(0, len(predictions), chunk_size)]\n",
    "\n",
    "i = 0\n",
    "print(f'Total # of chunks {len(qa_chunks)}')\n",
    "while i < len(qa_chunks):\n",
    "    print(f'starting chunk {i}')\n",
    "    try:\n",
    "        graded_output_chunk = eval_chain.evaluate(qa_chunks[i], qa_predictions[i], question_key = 'query', prediction_key = 'output')\n",
    "        graded_outputs.append(graded_output_chunk)\n",
    "        # wait between each chunk\n",
    "        time.sleep(60)\n",
    "    except:\n",
    "        print('going to next chunk')\n",
    "        continue\n",
    "    i+=1\n",
    "    \n",
    "# graded_outputs = eval_chain.evaluate(qa_list, predictions, question_key = 'query', prediction_key = 'output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "c56c1409-b9aa-463f-abd7-b56edf725d38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### 3c. Store LLM evaluated metrics in llmevaluationresults table\n",
    "llm_eval_predictions=[]\n",
    "graded_outputs_flat = [item for sublist in graded_outputs for item in sublist]\n",
    "\n",
    "for i, eg in enumerate(graded_outputs_flat):\n",
    "    grade = ''\n",
    "    try:\n",
    "        if 'GRADE: INCORRECT' in str(graded_outputs_flat[i]['results']):\n",
    "            grade = 'INCORRECT'\n",
    "        else:\n",
    "            grade = 'CORRECT'  \n",
    "    except:\n",
    "        print('failed to extract grade')\n",
    "\n",
    "    llm_eval_predictions.append({\n",
    "                \"query\": predictions[i]['query'],\n",
    "                \"llm\": predictions[i]['llm'],\n",
    "                \"context\": predictions[i]['context'],\n",
    "                \"output\": predictions[i]['output'],\n",
    "                \"trainingoutput\": predictions[i]['trainingoutput'],\n",
    "                \"evaluationmetric\": \"LLM-assisted evaluation with Claude\",\n",
    "                \"score\": grade,\n",
    "                \"feedback\": str(graded_outputs_flat[i]['results'])\n",
    "            })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4015ff5e-ddb2-4b3e-a5f6-01d586d8a25c",
   "metadata": {},
   "source": [
    "LLM-assisted evaluation provides significant better evaluation results compared to string evaluation. Yet it does not require insights into Faithfulness, Context Precision,Context Recall, Answer Relevancy,or Aspect Critiques), which would be helpful for a RAG use case like this. This is where libraries like ragas-langsmith can be helpful (requires an OpenAI API key)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055540da-ea14-449d-874e-007930d40f49",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\"https://d3q8adh3y5sxpk.cloudfront.net/meetingrecordings/modelevaluation/Slide8.jpeg\" alt=\"EvaluatingResults\" width=\"900\" height=\"550\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "201872ff-fac2-4104-b0dd-8ecaa25cff32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>llm</th>\n",
       "      <th>TOTAL_Count</th>\n",
       "      <th>CORRECT_Count</th>\n",
       "      <th>INCORRECT_Count</th>\n",
       "      <th>llm_eval_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anthropic.claude-v2</td>\n",
       "      <td>196</td>\n",
       "      <td>14</td>\n",
       "      <td>182</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>cohere.command-text-v14</td>\n",
       "      <td>196</td>\n",
       "      <td>18</td>\n",
       "      <td>178</td>\n",
       "      <td>0.091837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>jumpstart-dft-meta-textgeneration-llama-2-7b-f</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>0.012658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                llm  TOTAL_Count  \\\n",
       "0                               anthropic.claude-v2          196   \n",
       "196                         cohere.command-text-v14          196   \n",
       "392  jumpstart-dft-meta-textgeneration-llama-2-7b-f           79   \n",
       "\n",
       "     CORRECT_Count  INCORRECT_Count  llm_eval_accuracy  \n",
       "0               14              182           0.071429  \n",
       "196             18              178           0.091837  \n",
       "392              1               78           0.012658  "
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 3d. evaluating overall model accuracy\n",
    "\n",
    "# Count the number of CORRECT and INCORRECT evaluations for each LLM and evaluation method\n",
    "llm_eval_predictions_df = pd.DataFrame(llm_eval_predictions)\n",
    "\n",
    "# get value of grouby column\n",
    "llm_eval_predictions_df['llm'] = llm_eval_predictions_df['llm'].str.strip()\n",
    "llm_eval_predictions_df['CORRECT_Count'] = llm_eval_predictions_df.groupby('llm')['score'].transform(lambda x: (x == 'CORRECT').sum())\n",
    "llm_eval_predictions_df['INCORRECT_Count'] = llm_eval_predictions_df.groupby('llm')['score'].transform(lambda x: (x == 'INCORRECT').sum())\n",
    "llm_eval_predictions_df['llm_eval_accuracy'] = llm_eval_predictions_df['CORRECT_Count'] / (llm_eval_predictions_df['CORRECT_Count'] + llm_eval_predictions_df['INCORRECT_Count'])\n",
    "llm_eval_predictions_df['TOTAL_Count'] = llm_eval_predictions_df['CORRECT_Count'] + llm_eval_predictions_df['INCORRECT_Count']\n",
    "\n",
    "# remove all columns from dataframe except columns TOTAL_Count, CORRECT_Count, INCORRECT_Count, llm_eval_accuracy\n",
    "llm_eval_predictions_df = llm_eval_predictions_df[['llm','TOTAL_Count', 'CORRECT_Count', 'INCORRECT_Count', 'llm_eval_accuracy']]\n",
    "\n",
    "#remove all duplicate rows from llm_eval_predictions_df\n",
    "llm_eval_predictions_df = llm_eval_predictions_df.drop_duplicates()\n",
    "\n",
    "# Count the number of CORRECT and INCORRECT evaluations for each LLM and evaluation method\n",
    "string_eval_predictions_df = pd.DataFrame(string_eval_predictions)\n",
    "\n",
    "# get value of grouby column\n",
    "string_eval_predictions_df['llm'] = string_eval_predictions_df['llm'].str.strip()\n",
    "string_eval_predictions_df['CORRECT_Count'] = string_eval_predictions_df.groupby('llm')['score'].transform(lambda x: (x == 'CORRECT').sum())\n",
    "string_eval_predictions_df['INCORRECT_Count'] = string_eval_predictions_df.groupby('llm')['score'].transform(lambda x: (x == 'INCORRECT').sum())\n",
    "string_eval_predictions_df['llm_eval_accuracy'] = string_eval_predictions_df['CORRECT_Count'] / (string_eval_predictions_df['CORRECT_Count'] + string_eval_predictions_df['INCORRECT_Count'])\n",
    "string_eval_predictions_df['TOTAL_Count'] = string_eval_predictions_df['CORRECT_Count'] + string_eval_predictions_df['INCORRECT_Count']\n",
    "\n",
    "# remove all columns from dataframe except columns TOTAL_Count, CORRECT_Count, INCORRECT_Count, llm_eval_accuracy\n",
    "string_eval_predictions_df = string_eval_predictions_df[['llm','TOTAL_Count', 'CORRECT_Count', 'INCORRECT_Count', 'llm_eval_accuracy']]\n",
    "\n",
    "#remove all duplicate rows from llm_eval_predictions_df\n",
    "string_eval_predictions_df = string_eval_predictions_df.drop_duplicates()\n",
    "\n",
    "# show first 4 rows from llm_eval_predictions_df\n",
    "string_eval_predictions_df.head(4)\n",
    "\n",
    "# show first 4 rows from llm_eval_predictions_df\n",
    "#llm_eval_predictions_df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "8240c17e-081d-44f0-a9dc-8fc5448d49eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### 3e. visualize model accuracy\n",
    "# plot each row' accuracy column in overall_accuracy with matplotlib\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "categories = [\"NaiveJaccardSimilarity\", \"LLMEval\"]\n",
    "dataprep = []\n",
    "for index, row in llm_eval_predictions_df.iterrows():\n",
    "    llm_name = row['llm']\n",
    "    result_df = string_eval_predictions_df[string_eval_predictions_df['llm'] == llm_name]\n",
    "    value = result_df.loc[index, 'llm_eval_accuracy']\n",
    "    dataprep.append([llm_name, pd.to_numeric(value), pd.to_numeric(row['llm_eval_accuracy'])])\n",
    "\n",
    "data = {\n",
    "    'EvaluationMethod': [\"NaiveJaccardSimilarity\", \"LLMEval\"],\n",
    "    dataprep[0][0] : dataprep[0][1:],\n",
    "    dataprep[1][0]: dataprep[1][1:],\n",
    "    dataprep[2][0]: dataprep[2][1:]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Set the width of the bars and the number of series\n",
    "num_series = len(df.columns) - 1  # Subtract 1 to exclude the 'Category' column\n",
    "bar_width = 0.2\n",
    "bar_positions = np.arange(len(df))\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot each series\n",
    "for i, col in enumerate(df.columns[1:]):\n",
    "    offset = (i - (num_series - 1) / 2) * bar_width\n",
    "    ax.bar(bar_positions + offset, df[col], width=bar_width, label=col)\n",
    "\n",
    "# Set x-axis labels\n",
    "ax.set_xticks(bar_positions)\n",
    "ax.set_xticklabels(df['EvaluationMethod'])\n",
    "\n",
    "# Labeling and legend\n",
    "ax.set_xlabel('Model Evaliation')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('LLM Accuracy')\n",
    "ax.legend()\n",
    "\n",
    "# Show the chart\n",
    "plt.tight_layout()  # Optional: Adjust layout for better spacing\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd243dfa-7eab-4916-868b-243f57af4003",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\"https://d3q8adh3y5sxpk.cloudfront.net/meetingrecordings/modelevaluation/Slide9.jpeg\" alt=\"EvaluatingResults\" width=\"900\" height=\"550\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b361cb74-6902-491a-9e4f-33f67c605304",
   "metadata": {},
   "source": [
    "TO DO: Add guidance/documentation (along the lines of cost,performance, accuracy) - Harsha - open"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6c8ca6-57c0-4422-984f-03bef10f2c63",
   "metadata": {},
   "source": [
    "# What can be improved in the evaluation strategy?\n",
    "- Use other metrics than accuracy. Maybe a semantic similarity metric like the one proposed in \"Semantic Answer Similarity for Evaluating Question Answering Models\" (arXiv:2108.06130).\n",
    "\n",
    "- Evaluate each component of the system (see options above) in isolation. For example evaluate the retrieval system/strategy separately and not just the entire pipeline as a whole. You could evaluate the retrieval system by saving the chunks that were used/are relevant for the actual answer alongside with the questions and answers in the evaluation dataset. Then you can compare/evaluate which top k chunks are being selected during the evaluation and whether or not the retriever selected a chunk with the source truth and at which rank and experiment with the different retriever options and chain types.\n",
    "\n",
    "- Explore parsers/tools in conjunction with LLMs, e.g. eparse (https://github.com/ChrisPappalardo/eparse), unstructured (https://github.com/Unstructured-IO/unstructured), and/or Kor (https://eyurtsev.github.io/kor/tutorial.html)\n",
    "\n",
    "- Incorporate other dimensions such as performance/latency and cost in more detail into the evaluation as well to derive at a cost performance benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6879cd-dee2-49b9-89bc-e15f5479adc0",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "- LLMs are here to stay, and the evaluation of LLMs is still evolving, with new research and tooling being released on a regular basis.\n",
    "- While this notebook focused on LLM accuracy, it also highlights the importance of other dimesions such as cost and latency, and outlines a practical approach to model evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056f0737-9867-4935-94f6-e9bc148ac954",
   "metadata": {},
   "source": [
    "### SCRATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "845a991f-9e6a-48f2-adb1-4da765b1e14c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### alternative version without langchain for creating embeddings\n",
    "\n",
    "def get_embedding(body, modelId, accept, contentType):\n",
    "    response = bedrock_runtime.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "    embedding = response_body.get('embedding')\n",
    "    return embedding\n",
    "\n",
    "def embed_phrase(phrase):\n",
    "    body = json.dumps({\"inputText\": str(phrase)})\n",
    "    modelId = 'amazon.titan-embed-text-v1' #'amazon.titan-e1t-medium' # not available yet\n",
    "    contentType = 'application/json'\n",
    "    accept = 'application/json'\n",
    "    embedding = get_embedding(body, modelId, accept, contentType)\n",
    "    return embedding\n",
    "    \n",
    "def os_import(record, aos_client, index_name):\n",
    "    search_vector = embed_phrase(record)\n",
    "    aos_client.index(index=index_name,\n",
    "             body={\"vector_field\": search_vector,\n",
    "                   \"text\": record\n",
    "                  },\n",
    "            request_timeout=60*3,  # 3 minutes\n",
    "            )\n",
    "\n",
    "def query_opensearch(index_name, phrase, n=1):\n",
    "    search_vector = embed_phrase(phrase)\n",
    "    osquery={\n",
    "        \"_source\": {\n",
    "            \"exclude\": [ \"vector_field\" ]\n",
    "        },\n",
    "        \n",
    "      \"size\": n,\n",
    "      \"query\": {\n",
    "        \"knn\": {\n",
    "          \"vector_field\": {\n",
    "            \"vector\":search_vector,\n",
    "            \"k\":n\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "\n",
    "    res = aos_client.search(index=index_name, \n",
    "                           body=osquery,\n",
    "                           stored_fields=[\"text\"],\n",
    "                           explain = True)\n",
    "    print(res)\n",
    "    result = {\n",
    "            \"text\":\"\"\n",
    "        }\n",
    "    if res['hits']['hits']:\n",
    "        top_result = res['hits']['hits'][0]\n",
    "    \n",
    "        result = {\n",
    "            \"text\":top_result['_source']['text'],\n",
    "\n",
    "        }\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "### test embedding\n",
    "#embed_phrase(\"pairs well with chocolate\")\n",
    "\n",
    "# test insert\n",
    "# token_text_list\n",
    "#for record in char_text_list: \n",
    "#    #print(record.page_content)\n",
    "#    os_import(record.page_content, aos_client, index_name)\n",
    "\n",
    "#for record in token_text_list: \n",
    "    #print(record.page_content)\n",
    "#    os_import(record.page_content, aos_client, index_name)\n",
    "    \n",
    "#for record in token_text_list: \n",
    "#    print(record.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "299f3f70-a164-4d36-9898-ba45d9898e59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"generated_text\": \" The A3 is a compact car that is a lot more than just a compact car. It's a compact car that is a lot more than just a compact car. It's a compact car that is a lot more than just a compact car. It's a compact car that is a lot more than just a compact car. It's a compact car that is a lot more than just a compact car. It's a compact car that is a lot more than just a compact car. It's a compact car that is a lot more than just a compact car. It's a compact car\"}\n"
     ]
    }
   ],
   "source": [
    "# SageMaker endpoint query\n",
    "\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "smr_client = boto3.client(\"sagemaker-runtime\")\n",
    "from sagemaker.predictor import Predictor\n",
    "\n",
    "def query_endpoint(payload, endpoint_name):\n",
    "    \"\"\"Query endpoint and print the response\"\"\"\n",
    "\n",
    "    response_model = smr_client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        Body=payload,\n",
    "        ContentType=\"application/json\",\n",
    "    )\n",
    "\n",
    "    generated_text = response_model[\"Body\"].read().decode(\"utf8\")\n",
    "    print(generated_text)\n",
    "\n",
    "\n",
    "payload = json.dumps(\n",
    "    {\n",
    "        \"inputs\": \"What is so special about Amazon?\",\n",
    "        \"parameters\": {\"max_new_tokens\": 126, \"no_repeat_ngram_size\": 3},\n",
    "    }\n",
    ")\n",
    "\n",
    "endpoint_name = \"lmi-model-falcon-7b-2023-08-27-17-52-54-260\"\n",
    "query_endpoint(payload, endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "15756e76-511a-4928-a5db-c80ac84c56bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# bedrock helper methods for langchain\n",
    "\n",
    "def get_inference_parameters(model): #return a default set of parameters based on the model's provider\n",
    "    bedrock_model_provider = model.split('.')[0] #grab the model provider from the first part of the model id\n",
    "    \n",
    "    if (bedrock_model_provider == 'anthropic'): #Anthropic model\n",
    "        return { #anthropic\n",
    "            \"max_tokens_to_sample\": 545,\n",
    "            \"temperature\": 0, \n",
    "            \"top_k\": 250, \n",
    "            \"top_p\": 1, \n",
    "            \"stop_sequences\": [\"\\n\\nHuman:\"] \n",
    "           }\n",
    "    \n",
    "    elif (bedrock_model_provider == 'ai21'): #AI21\n",
    "        return { #AI21\n",
    "            \"maxTokens\": 545, \n",
    "            \"temperature\": 0, \n",
    "            \"topP\": 0.5, \n",
    "            \"stopSequences\": [], \n",
    "            \"countPenalty\": {\"scale\": 0 }, \n",
    "            \"presencePenalty\": {\"scale\": 0 }, \n",
    "            \"frequencyPenalty\": {\"scale\": 0 } \n",
    "           }\n",
    "\n",
    "    elif (bedrock_model_provider == 'cohere'):\n",
    "        \n",
    "        return { \n",
    "            \"max_tokens\": 545, \n",
    "            \"temperature\": 0, \n",
    "            \"return_likelihood\": \"GENERATION\",\n",
    "            \"stop_sequences\": [\"\\n\\nHuman:\"],\n",
    "            \n",
    "           }\n",
    "    \n",
    "    else: #Amazon\n",
    "        #For the LangChain Bedrock implementation, these parameters will be added to the \n",
    "        #textGenerationConfig item that LangChain creates for us\n",
    "        return { \n",
    "            \"maxTokenCount\": 545, \n",
    "            \"stopSequences\": [], \n",
    "            \"temperature\": 0, \n",
    "            \"topP\": 0.9 \n",
    "        }\n",
    "\n",
    "def get_text_response(model, input_content): #text-to-text client function\n",
    "    \n",
    "    model_kwargs = get_inference_parameters(model) #get the default parameters based on the selected model\n",
    "    \n",
    "    llm = Bedrock( #create a Bedrock llm client\n",
    "        region_name=os.environ.get(\"BEDROCK_REGION_NAME\"), #sets the region name (if not the default)\n",
    "        endpoint_url=os.environ.get(\"BEDROCK_ENDPOINT_URL\"), #sets the endpoint URL (if necessary)\n",
    "        model_id=model, #use the requested model\n",
    "        model_kwargs = model_kwargs\n",
    "    )\n",
    "    return llm.predict(input_content) #return a response to the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107a0857-eb00-46cd-8795-ce3333d2b680",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# invoke Bedrock models with langchain helper method\n",
    "# cohere.command-text-v14\n",
    "# amazon.titan-text-express-v1\n",
    "# anthropic.claude-v2\n",
    "start = time.time()\n",
    "response = get_text_response(\"anthropic.claude-v2\", \"What is a donut?\")\n",
    "print(response)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "53a2abe7-0968-4a38-a93c-dd9501e25f81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generations': [{'id': '4c74edb9-bcd1-48f3-8370-a48896e7b9bb', 'text': ' A donut, or doughnut, is a small fried cake of sweetened dough. Donuts are usually ring-shaped, and typically have a hole in the center. Donuts are popular around the world and are enjoyed by many people. \\n\\nThere are many different types of donuts, including:\\n\\n- Cake donuts, which are made from a cake-like batter and are typically smaller and more dense than other types of donuts.\\n- Yeast donuts, which are made from a yeast dough and are often larger and fluffier than cake donuts.\\n- Filled donuts, which are donuts that are injected with a filling, such as jelly or cream.\\n- Frosted donuts, which are donuts that are topped with a frosting, such as chocolate or vanilla.\\n- Glazed donuts, which are donuts that are coated with a glaze, such as a sugar or honey glaze.\\n\\nDonuts are often served as a dessert or a snack, and are often accompanied by coffee or other beverages. They can be purchased from donut shops, supermarkets, and other food retailers.'}], 'id': '2b903489-f521-4ff5-a876-01d42750bc89', 'prompt': 'Human: What is a donut?\\n                 Assistant: \\n              '}\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# invoke Bedrock model\n",
    "# cohere.command-text-v14\n",
    "# amazon.titan-text-express-v1\n",
    "# anthropic.claude-v2\n",
    "import json\n",
    "modelId = 'cohere.command-text-v14' # change this to use a different version from the model provider\n",
    "\n",
    "accept = '*/*'\n",
    "contentType = 'application/json'\n",
    "\n",
    "prompt_data = \"\"\"Human: What is a donut?\n",
    "                 Assistant: \n",
    "              \"\"\"\n",
    "\n",
    "model_kwargs = {\n",
    "                \"max_tokens\": 545,\n",
    "                \"temperature\": 0,\n",
    "                \n",
    "               }\n",
    "               \n",
    "model_kwargs[\"prompt\"] = prompt_data\n",
    "body = json.dumps(model_kwargs)\n",
    "\n",
    "response = bedrock_runtime.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "response_body = json.loads(response.get('body').read())\n",
    "print(response_body)\n",
    "print(response_body.get('completion'))"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
